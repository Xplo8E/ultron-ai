# src/ultron/reviewer.py
import os
import json
import re
from typing import Optional

import google.generativeai as genai
from dotenv import load_dotenv

from .models import BatchReviewData # Changed from ReviewData
from .constants import (
    AVAILABLE_MODELS, DEFAULT_MODEL_KEY, DEFAULT_REVIEW_PROMPT_TEMPLATE,
    USER_CONTEXT_TEMPLATE, USER_FRAMEWORK_CONTEXT_TEMPLATE,
    USER_SECURITY_REQUIREMENTS_TEMPLATE, MULTI_FILE_INPUT_FORMAT_DESCRIPTION
)

load_dotenv()
GEMINI_API_KEY_LOADED = os.getenv("GEMINI_API_KEY")

if GEMINI_API_KEY_LOADED:
    genai.configure(api_key=GEMINI_API_KEY_LOADED)

def get_gemini_review(
    code_batch: str, # This is now the concatenated string of multiple files
    primary_language_hint: str, # e.g., 'php', 'javascript', or 'auto'
    model_key: str = DEFAULT_MODEL_KEY,
    additional_context: Optional[str] = None,
    frameworks_libraries: Optional[str] = None,
    security_requirements: Optional[str] = None,
) -> Optional[BatchReviewData]:
    """
    Sends a batch of code files (formatted as a single string) to the Gemini API for review.
    """
    if not GEMINI_API_KEY_LOADED:
        return BatchReviewData(error="GEMINI_API_KEY not configured.")

    user_context_section_str = USER_CONTEXT_TEMPLATE.format(additional_context=additional_context) \
        if additional_context and additional_context.strip() else ""
    
    frameworks_list_str = frameworks_libraries if frameworks_libraries and frameworks_libraries.strip() else "Not specified"
    user_framework_context_section_str = USER_FRAMEWORK_CONTEXT_TEMPLATE.format(frameworks_libraries=frameworks_list_str) \
        if frameworks_libraries and frameworks_libraries.strip() else ""

    user_security_requirements_section_str = USER_SECURITY_REQUIREMENTS_TEMPLATE.format(security_requirements=security_requirements) \
        if security_requirements and security_requirements.strip() else ""

    prompt = DEFAULT_REVIEW_PROMPT_TEMPLATE.format(
        MULTI_FILE_INPUT_FORMAT_DESCRIPTION=MULTI_FILE_INPUT_FORMAT_DESCRIPTION,
        user_context_section=user_context_section_str,
        user_framework_context_section=user_framework_context_section_str,
        user_security_requirements_section=user_security_requirements_section_str,
        frameworks_libraries_list=frameworks_list_str,
        language=primary_language_hint,
        code_batch_to_review=code_batch
    )

    actual_model_name = AVAILABLE_MODELS.get(model_key, AVAILABLE_MODELS[DEFAULT_MODEL_KEY])
    print(f"Using Gemini model: {actual_model_name} for the batch.")

    model_instance = genai.GenerativeModel(
        actual_model_name,
        generation_config={
            "response_mime_type": "application/json",
            "temperature": 0.1,
            "top_k": 20,
            "top_p": 0.8,
        },
        safety_settings=[
            {
                "category": "HARM_CATEGORY_DANGEROUS",
                "threshold": "BLOCK_NONE"
            }
        ]
    )

    total_input_tokens_count = 0
    try:
        total_input_tokens_count = model_instance.count_tokens(prompt).total_tokens
        print(f"Total estimated tokens for this batch request: {total_input_tokens_count}")
    except Exception as e:
        print(f"Warning: Could not count total tokens for batch - {e}")

    try:
        print("Sending batch request to Gemini API...")
        response = model_instance.generate_content(
            prompt,
            generation_config={
                "response_mime_type": "application/json",
                "temperature": 0.1,
                "top_k": 20,
                "top_p": 0.8,
                "candidate_count": 1,
                "stop_sequences": ["```"],  # Prevent code block formatting
            }
        )

        if not response.candidates:
            error_message = "No content generated by API for the batch."
            if response.prompt_feedback and response.prompt_feedback.block_reason:
                error_message = f"Batch content generation blocked. Reason: {response.prompt_feedback.block_reason}."
                if response.prompt_feedback.safety_ratings:
                    error_message += f" Safety Ratings: {response.prompt_feedback.safety_ratings}"
            return BatchReviewData(error=error_message)

        raw_json_text = response.text.strip()
        
        # Handle empty response
        if not raw_json_text:
            return BatchReviewData(
                error="Empty response from API",
                overall_batch_summary="Error: Empty response received",
                file_reviews=[],
                llm_processing_notes="API returned empty response"
            )

        # Debug logging
        print(f"Raw response length: {len(raw_json_text)} characters")
        print("Response starts with:", raw_json_text[:100] + "..." if len(raw_json_text) > 100 else raw_json_text)
        
        # First try to find JSON block with or without language identifier
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", raw_json_text, re.DOTALL | re.IGNORECASE)
        if match:
            cleaned_json_text = match.group(1).strip()
            print("Found JSON block in code fence")
        else:
            # If no code block, try to find the first { and last } for a complete JSON object
            start_idx = raw_json_text.find('{')
            end_idx = raw_json_text.rfind('}')
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                cleaned_json_text = raw_json_text[start_idx:end_idx + 1].strip()
                print("Found JSON object using brace matching")
            else:
                # If no JSON structure found, create a structured response
                print("No JSON structure found, creating fallback response")
                cleaned_json_text = json.dumps({
                    "error": None,
                    "overallBatchSummary": "Warning: Response was not in JSON format",
                    "fileReviews": [{
                        "filePath": "response.txt",
                        "summary": "Raw response (not JSON)",
                        "highConfidenceVulnerabilities": [],
                        "lowPrioritySuggestions": [],
                        "error": None,
                        "languageDetected": None
                    }],
                    "llmProcessingNotes": raw_json_text  # Store the raw response here
                })

        try:
            # Attempt to parse as JSON
            try:
                parsed_data = json.loads(cleaned_json_text)
            except json.JSONDecodeError as json_err:
                print(f"JSON parsing error: {json_err}")
                print("Failed JSON content:", cleaned_json_text[:200] + "..." if len(cleaned_json_text) > 200 else cleaned_json_text)
                raise  # Re-raise to be caught by outer try block
            
            # Ensure the response has the required structure
            if not isinstance(parsed_data, dict):
                parsed_data = {
                    "error": None,
                    "overallBatchSummary": "Warning: Response was not a JSON object",
                    "fileReviews": [{
                        "filePath": "response.txt",
                        "summary": "Raw response (not proper JSON object)",
                        "highConfidenceVulnerabilities": [],
                        "lowPrioritySuggestions": [],
                        "error": None,
                        "languageDetected": None
                    }],
                    "llmProcessingNotes": cleaned_json_text
                }
            
            # Ensure required fields exist
            if "fileReviews" not in parsed_data:
                parsed_data["fileReviews"] = []
            if "overallBatchSummary" not in parsed_data:
                parsed_data["overallBatchSummary"] = ""
            
            batch_review_obj = BatchReviewData(**parsed_data)
            batch_review_obj.total_input_tokens = total_input_tokens_count
            return batch_review_obj

        except Exception as e:
            print(f"Error processing response: {e}")
            return BatchReviewData(
                error=f"Error processing response: {e}",
                overall_batch_summary="Error processing LLM response",
                file_reviews=[],
                llm_processing_notes=cleaned_json_text
            )

    except Exception as e:
        err_msg = f"Gemini API call error for batch: {e}"
        try:
            if 'response' in locals() and response.prompt_feedback and response.prompt_feedback.block_reason:
                err_msg += f". API Block Reason: {response.prompt_feedback.block_reason}"
        except AttributeError: pass 
        except NameError: pass 
        return BatchReviewData(error=err_msg)