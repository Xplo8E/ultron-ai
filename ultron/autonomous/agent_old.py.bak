# ultron/autonomous/agent.py
"""
Ultron Autonomous Agent - Refactored for modularity and clarity.
The main agent orchestration class that coordinates LLM interactions with tools.
"""

import os
import time
import re
from pathlib import Path
from datetime import datetime
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from rich.text import Text
from google.genai import Client, types
from google.api_core import exceptions as google_exceptions
from pprint import pformat

from .config import AgentConfig
from .prompts import get_initial_prompt
from .tool_handler import ToolHandler
from .tools import get_directory_tree
from ..core.constants import AVAILABLE_MODELS, MODELS_SUPPORTING_THINKING  

console = Console()

class AutonomousAgent:
    """
    The main autonomous agent class. Now lean and focused on orchestrating
    the conversation with the LLM while delegating tool execution and 
    configuration management to specialized components.
    """
    
    def __init__(self, codebase_path: str, model_key: str, mission: str, verbose: bool = False, log_dir: str = "logs"):
        """
        Initialize the autonomous agent with modular components.
        
        Args:
            codebase_path: Path to the codebase to analyze
            model_key: Key identifying which model to use
            mission: The specific mission or goal for the agent
            verbose: Whether to enable verbose logging
            log_dir: Directory for log files
        """
        # --- 1. Configuration Setup ---
        log_dir_path = Path(log_dir)
        log_dir_path.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir_path / f"ultron_run_{timestamp}.log"
        
        self.config = AgentConfig(
            codebase_path=Path(codebase_path).resolve(),
            model_key=model_key,
            mission=mission,
            log_file_path=log_file,
            verbose=verbose
        )
        
        # --- 2. Model Configuration ---
        self.supports_thinking = self.config.model_key in MODELS_SUPPORTING_THINKING
        
        # --- 3. Tool Management ---
        self.tool_handler = ToolHandler(codebase_path=self.config.codebase_path)
        
        # --- MODIFIED: Define all tools for the model ---
        self.tools = [
            types.Tool(
                function_declarations=[
                    types.FunctionDeclaration(
                        name="read_file_content",
                        description="Reads the full text content of a single file. The file path must be relative to the project root.",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={"file_path": types.Schema(type=types.Type.STRING, description="Relative path to the file from project root.")},
                            required=["file_path"]
                        )
                    ),
                    types.FunctionDeclaration(
                        name="search_pattern",
                        description="Searches for a regex pattern within a single file and returns matching lines with line numbers.",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={
                                "file_path": types.Schema(type=types.Type.STRING, description="Relative path to the file."),
                                "regex_pattern": types.Schema(type=types.Type.STRING, description="The regex pattern to search for.")
                            },
                            required=["file_path", "regex_pattern"]
                        )
                    ),
                    types.FunctionDeclaration(
                        name="list_functions",
                        description="Lists all function and class method definitions in a Python (.py) file.",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={"file_path": types.Schema(type=types.Type.STRING, description="Relative path to the Python file.")},
                            required=["file_path"]
                        )
                    ),
                    types.FunctionDeclaration(
                        name="find_taint_sources_and_sinks",
                        description="Scans a file to find lines containing potential sources (e.g., user input) and sinks (e.g., command execution).",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={
                                "file_path": types.Schema(type=types.Type.STRING, description="Relative path to the file."),
                                "sources": types.Schema(type=types.Type.ARRAY, items=types.Schema(type=types.Type.STRING), description="Keywords for untrusted data sources (e.g., 'request.args', 'os.environ')."),
                                "sinks": types.Schema(type=types.Type.ARRAY, items=types.Schema(type=types.Type.STRING), description="Keywords for dangerous sinks (e.g., 'eval', 'subprocess.run').")
                            },
                            required=["file_path", "sources", "sinks"]
                        )
                    ),
                    # --- NEW: Add the search_codebase tool declaration ---
                    types.FunctionDeclaration(
                        name="search_codebase",
                        description="Recursively searches the entire codebase for a regex pattern. Use this to find all occurrences of a function, setting, or keyword across all files.",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={
                                "regex_pattern": types.Schema(type=types.Type.STRING, description="The regex pattern to search for globally.")
                            },
                            required=["regex_pattern"]
                        )
                    ),
                    
                    # --- NEW TOOL DECLARATIONS ---
                    types.FunctionDeclaration(
                        name="write_to_file",
                        description="Writes or overwrites a file with the provided string content. Use this to create Proof of Concept (PoC) files, test scripts, or suggested code patches.",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={
                                "file_path": types.Schema(type=types.Type.STRING, description="Relative path from the project root for the file to be created/overwritten."),
                                "content": types.Schema(type=types.Type.STRING, description="The full string content to write to the file.")
                            },
                            required=["file_path", "content"]
                        )
                    ),
                    types.FunctionDeclaration(
                        name="execute_shell_command",
                        description="Executes a shell command in the project's root directory. Returns the exit code, stdout, and stderr. Essential for compiling, running tests, or executing the application with a PoC.",
                        parameters=types.Schema(
                            type=types.Type.OBJECT,
                            properties={
                                "command": types.Schema(type=types.Type.STRING, description="The shell command to execute.")
                            },
                            required=["command"]
                        )
                    )
                ]
            )
        ]
        
        # --- MODIFIED: Map all tool handlers ---
        self.tool_handlers = {
            "read_file_content": self.read_file_content,
            "search_pattern": self.search_pattern,
            "list_functions": self.list_functions,
            "find_taint_sources_and_sinks": self.find_taint_sources_and_sinks,
            "search_codebase": self.search_codebase,
            "write_to_file": self.handle_write_to_file,                 # <--- ADD THIS
            "execute_shell_command": self.handle_execute_shell_command,  # <--- ADD THIS
        }

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable not set.")
        
        self.client = Client(api_key=api_key)

    # --- NEW: Helper method for logging ---
    def _log(self, content: str):
        """Appends content to the run's log file."""
        with open(self.log_file_path, "a", encoding="utf-8") as f:
            f.write(content + "\n")

    def _resolve_and_validate_path(self, file_path: str) -> tuple[Path | None, str | None]:
        """Resolves a relative path to an absolute one and provides helpful errors."""
        if '..' in Path(file_path).parts or Path(file_path).is_absolute():
            return None, "Error: Path traversal or absolute paths are not allowed. Use relative paths from the project root."
        
        absolute_path = (self.codebase_path / file_path).resolve()
        
        if not str(absolute_path).startswith(str(self.codebase_path)):
            return None, "Error: Path traversal attempt detected. Access denied."

        if absolute_path.is_file():
            return absolute_path, None  # Success!

        # --- Enhanced Error Handling ---
        if absolute_path.is_dir():
            try:
                contents = [p.name for p in absolute_path.iterdir()]
                contents_str = ", ".join(sorted(contents)) if contents else "It is empty."
                return None, f"Error: Path '{file_path}' is a directory, not a file. Its contents are: [{contents_str}]."
            except Exception as e:
                return None, f"Error: Path '{file_path}' is a directory, but its contents could not be read. Reason: {e}"

        # If the path doesn't exist, check its parent for context.
        parent_dir = absolute_path.parent
        if parent_dir.is_dir():
            try:
                contents = [p.name for p in parent_dir.iterdir()]
                contents_str = ", ".join(sorted(contents)) if contents else "It is empty."
                relative_parent = parent_dir.relative_to(self.codebase_path)
                relative_parent_str = str(relative_parent) if str(relative_parent) != '.' else 'the root directory'
                return None, f"Error: File not found at path '{file_path}'. The parent directory '{relative_parent_str}' exists and contains: [{contents_str}]."
            except Exception as e:
                return None, f"Error: File not found at path '{file_path}'. The parent directory exists, but its contents could not be read. Reason: {e}"
        else:
            relative_parent = parent_dir.relative_to(self.codebase_path)
            return None, f"Error: Cannot access path '{file_path}' because its directory '{relative_parent}' does not exist."

    def read_file_content(self, file_path: str) -> str:
        """Handler for reading file content."""
        console.print(f"**[Tool Call]** `read_file_content(file_path='{file_path}')`")
        absolute_path, error = self._resolve_and_validate_path(file_path)
        if error:
            return error
        try:
            with open(absolute_path, 'r', encoding='utf-8', errors='ignore') as f:
                return f.read()
        except Exception as e:
            return f"Error: Could not read file '{file_path}'. Reason: {e}"

    # --- NEW TOOL HANDLER METHODS ---

    def search_pattern(self, file_path: str, regex_pattern: str) -> str:
        """Handler for searching a pattern in a file."""
        console.print(f"**[Tool Call]** `search_pattern(file_path='{file_path}', regex_pattern='{regex_pattern}')`")
        absolute_path, error = self._resolve_and_validate_path(file_path)
        if error:
            return error
        return search_pattern_in_file(str(absolute_path), regex_pattern)

    def list_functions(self, file_path: str) -> str:
        """Handler for listing functions in a Python file."""
        console.print(f"**[Tool Call]** `list_functions(file_path='{file_path}')`")
        absolute_path, error = self._resolve_and_validate_path(file_path)
        if error:
            return error
        return list_functions_in_file(str(absolute_path))

    def find_taint_sources_and_sinks(self, file_path: str, sources: list[str], sinks: list[str]) -> str:
        """Handler for finding taint sources and sinks."""
        console.print(f"**[Tool Call]** `find_taint_sources_and_sinks(file_path='{file_path}', sources={sources}, sinks={sinks})`")
        absolute_path, error = self._resolve_and_validate_path(file_path)
        if error:
            return error
        return find_taints_in_file(str(absolute_path), sources, sinks)

    # --- NEW: Add the handler method for the new tool ---
    def search_codebase(self, regex_pattern: str) -> str:
        """Handler for searching the entire codebase."""
        console.print(f"**[Tool Call]** `search_codebase(regex_pattern='{regex_pattern}')`")
        # The core logic is in tools.py, so we just call it.
        # No path validation is needed as it operates from the root by design.
        return search_codebase(str(self.codebase_path), regex_pattern)

    # --- NEW TOOL HANDLER METHODS ---

    def handle_write_to_file(self, file_path: str, content: str) -> str:
        """Handler for writing a file, ensuring it's within the codebase bounds."""
        console.print(f"**[Tool Call]** `write_to_file(file_path='{file_path}', ...)`")
        
        # We must prevent writing files outside the project directory.
        if '..' in Path(file_path).parts or Path(file_path).is_absolute():
            return "Error: Path traversal ('..') or absolute paths are not allowed. Use relative paths from the project root."
        
        absolute_path = (self.codebase_path / file_path).resolve()
        
        if not str(absolute_path).startswith(str(self.codebase_path)):
            return "Error: Security violation. Attempted to write file outside of the project codebase."
            
        return write_to_file(str(absolute_path), content)

    def handle_execute_shell_command(self, command: str) -> str:
        """Handler for executing a shell command within the project root."""
        console.print(f"**[Tool Call]** `execute_shell_command(command='{command}')`")
        # All commands are executed from the root of the codebase for safety and consistency.
        return execute_shell_command(command, str(self.codebase_path))
        
    def _create_initial_prompt(self):
        directory_tree = get_directory_tree(str(self.codebase_path))
        mission = self.mission or "Perform a deep static security audit to discover the most critical, practically exploitable vulnerabilities in the codebase and produce working Proofs of Concept."

        return f"""
    You are an expert security code reviewer. Your primary goal is to identify **valid, practically exploitable vulnerabilities** with **verifiable Proofs of Concept (POCs)**. 
    
    Use **chain-of-thought**: clearly articulate your hypothesis, then select the minimal tool call to validate it. Iterate this loop until you either confirm an exploit or exhaust relevant code paths.

    **MISSION**: {mission}

    **PROJECT STRUCTURE**:
    {directory_tree}

    

    ---

    ## CORE OPERATING PRINCIPLE: ONE ACTION PER TURN

    This is your most important rule. You operate in a strict turn-based loop. Each of your responses MUST result in **EITHER** a `thought` process that ends in a single tool call, **OR** a final report. **NEVER both in the same response.**

    1.  **Investigation Turn (Thought -> Tool Call):**
        - Your thought process MUST analyze the evidence so far.
        - State a clear, testable hypothesis.
        - Conclude with a single, precise tool call to test that hypothesis.

    2.  **Conclusion Turn (Final Report):**
        - This is a terminal action. You only take this turn when you have completed the "Final Verification Checklist" and have all the evidence needed.
        - This is the **only** time you do not call a tool. Your entire response will be *only* the markdown report.

    ---


    ## CRITICAL: FINAL VERIFICATION CHECKLIST
    
    You are **FORBIDDEN** from producing a "Conclusion Turn" and writing a final report until you can answer YES to all of these questions based on **prior tool outputs**:

    1.  **Trace Complete?** Have I used tools (`search_codebase`, etc.) to trace the full data flow from the untrusted source to the dangerous sink?
    2.  **No Sanitization?** Have I used tools to search for and confirm that sanitization functions along the data path are absent, flawed, or bypassed?
    3.  **Conditions Met?** Have I used tools to verify the conditions required for the exploit (e.g., a required feature flag is enabled by default)?
    4.  **PoC is Grounded in Reality?** Is my Proof of Concept based on **real, documented commands and directives** for the target technology (e.g., Nginx, Bash)? Have I avoided inventing functions or commands? If the exploit is complex (e.g., requires multiple steps), have I accurately represented this?

    ---

    **Requirements for Proofs of Concept (POCs):**
    -   Write complete executable code (e.g., `curl` commands, Python scripts, JavaScript payloads, etc.).
    -   Include exact endpoints, parameters, and payload values needed.
    -   Specify HTTP methods, headers, and request/response formats where applicable.
    -   Show both the malicious input AND the expected malicious output.
    -   If chaining multiple steps, number them and show the output of each step.
    -   For client-side exploits, provide the exact HTML/JS payload and how to deliver it.

    ## TOOL USAGE GUIDELINES

    - **Recovery from Failure**: If a specialized tool like `list_functions` fails, it's likely not a valid Python file. Your next step should be to use `read_file_content` to understand its contents and purpose.
    - **`find_taint_sources_and_sinks` Strategy**: If this tool returns "No matches found," **DO NOT** assume the file is safe. This often means your source/sink keywords are wrong for the project's framework. Your next step must be to use `read_file_content` to identify the actual functions used for handling input and executing dangerous operations, then call `find_taint_sources_and_sinks` again with the correct keywords.
    - **File Not Found Errors**: If a tool returns a "File not found" or "Directory not found" error, carefully read the error message. It will often contain a list of files and directories that *do* exist, which you can use to correct the path in your next tool call.

    ---

    ## CORE OPERATING PRINCIPLE: HYPOTHESIZE, TEST, VERIFY

    You operate in a strict loop. Each turn, you EITHER state a hypothesis and call one tool to test it, OR you provide a final report.

    1.  **Static Analysis (Code Review):** Use tools like `read_file_content` and `search_codebase` to understand the code and form a hypothesis about a potential vulnerability.
    2.  **Dynamic Analysis (Interaction):** Once you have a plausible hypothesis, you must move to dynamic testing. This is the only way to confirm a real-world exploit.

    ---

    ## DYNAMIC ANALYSIS & PoC WORKFLOW

    To confirm a vulnerability, follow these generalized steps:

    1.  üß† **Form a Hypothesis**: Based on your static analysis, state what you believe the vulnerability is and how it can be triggered. For example, "I believe that providing a specially crafted JSON object to the `/api/v1/user` endpoint will cause a deserialization error leading to remote code execution."

    2.  ‚úçÔ∏è **Create the PoC**: Use the `write_to_file` tool to create the necessary files for your test. This could be:
        *   A file with a malicious payload (e.g., `poc.json`, `malicious.xml`, `input.txt`).
        *   A script to automate the attack (e.g., `exploit.py` that uses `requests`, `poc.sh` that uses `curl`).

    3.  ‚ö° **Execute and Test**: Use the `execute_shell_command` tool to run your test. This is highly dependent on the project:
        *   **For compiled languages (C, C++, Go, Java):** You may first need to run a build command (e.g., `make`, `mvn package`). Then, execute the compiled binary with your PoC file as input (e.g., `./app < poc.txt`).
        *   **For interpreted languages (Python, Node.js, Ruby):** You can directly run your attack script (e.g., `python exploit.py`) or run the main application server.
        *   **For command-line tools:** You can pipe your payload to the tool (e.g., `cat poc.txt | ./vulnerable_parser`).

    4.  üî¨ **Observe the Result**: Analyze the `Exit Code`, `STDOUT`, and `STDERR` from `execute_shell_command`.
        *   An `Exit Code` other than `0` often indicates a crash.
        *   `STDERR` containing `Segmentation fault`, `AddressSanitizer`, `panic`, or a stack trace is a strong signal of a vulnerability.
        *   `STDOUT` might reveal leaked information or unexpected behavior.

    5.  ‚úÖ **Conclude**: If the dynamic test confirms the vulnerability (e.g., a crash, unexpected output), you have sufficient evidence. Stop using tools and write your final report. If it fails, analyze the output to refine your hypothesis and try again.

    ---

    ## REPORT TEMPLATES
    
    ### If a vulnerability is found:
    ```markdown
    # ULTRON-AI Security Finding
    
    **Vulnerability:** [Concise title]
    **Severity:** [Critical | High | Medium | Low]
    **CWE:** [CWE-XX]
    **Confidence:** [High | Medium] 
    # High: The PoC uses real, documented commands and is highly likely to work.
    # Medium: The PoC is conceptual. It demonstrates the flaw, but the specific commands may need adaptation.

    ---

    ### Description
    [Detailed explanation of the flaw and its root cause.]

    ### Attack Chain
    [Step-by-step exploitation path from entry point to impact. For complex exploits, number the steps clearly.]

    ### Proof of Concept (PoC)
    ```bash
    # Working PoC with necessary commands or script
    echo '<payload>' | exploit_tool --target /vulnerable_endpoint
    ```

    ### Remediation
    [Concrete code or config changes to fix the issue.]
    ```

    ### If no exploitable vulnerabilities are identified:
    ```markdown
    # ULTRON-AI Security Analysis Conclusion

    **Status:** No high-confidence, practically exploitable vulnerabilities identified.

    ---

    ### Analysis Summary
    - [File/Component A]: checks and evidence of safety.
    - [File/Component B]: ...

    ### Overall Conclusion
    The codebase is secure against the defined threat model.
    ```

    ---

    **RULES:**
    - **Your PoC must be grounded in reality.** Only use commands, flags, and directives that are documented for the target technology. **DO NOT INVENT COMMANDS.** If you are not certain how to write a working PoC, explain the conceptual attack chain and set the Confidence to "Medium".
    - **A code comment is a HINT, not a confirmation.** You MUST use tools to verify all claims and data paths.
    - **Each turn must end in a tool call**, unless you have completed the checklist and are writing the final report.
    - **If you state that your next step is to use a tool, you MUST end your turn by calling that tool.** Do not state a plan and then write a report in the same turn.
    - The report **MUST NOT** be wrapped in code fences (e.g., ` ```markdown `) and **MUST NOT** have any other text, reasoning, or conversation before or after it.
    - **Do not** include any text beyond the specified templates.
    - **Do not** report style issues, theoretical risks, or unproven best practices. Focus only on exploitable vulnerabilities.

    Begin with your first hypothesis and corresponding tool call.
    """


    def run(self, max_turns=200) -> str:
        # --- MODIFIED: Announce log file creation ---
        console.print(Panel(f"üìù Logging full transcript to [bold cyan]{self.log_file_path}[/bold cyan]", style="blue"))
        
        initial_prompt = self._create_initial_prompt()
        self._log(f"\n--- Initial Prompt ---\n{initial_prompt}") # Log initial prompt
        chat_history = [
            types.Content(role="user", parts=[types.Part(text=initial_prompt)])
        ]
        final_report = None

        for turn in range(max_turns):
            turn_text = Text(f"ü§ñ ULTRON TURN {turn + 1}/{max_turns}", style="bold white")
            console.print(Panel(turn_text, style="bold cyan", padding=(0, 1)))
            self._log(f"\n\n{'='*20} TURN {turn + 1}/{max_turns} {'='*20}")

            # --- MODIFIED: Log the request being sent ---
            self._log("\n--- Request to Model ---")
            for message in chat_history:
                self._log(f"Role: {message.role}")
                for part in message.parts:
                    log_part_content = ""
                    if hasattr(part, 'text') and part.text:
                        log_part_content = f"Text: {part.text}"
                    elif hasattr(part, 'function_call'):
                        log_part_content = f"Function Call: {part.function_call}"
                    elif hasattr(part, 'function_response'):
                        log_part_content = f"Function Response: {part.function_response}"
                    self._log(log_part_content)
                self._log("-" * 10)

            if self.verbose:
                console.print("[bold cyan]‚û°Ô∏è Sending Request to Model...[/bold cyan]")
                for message in chat_history:
                    console.print(f"Role: {message.role}")
                    text_content = ""
                    for part in message.parts:
                        if hasattr(part, 'text') and part.text:
                            text_content += part.text + "\n.........................\n"
                    if text_content:
                        console.print(f"Content: {text_content}")
                console.print("-" * 20)
            
            config_args = {
                "tools": self.tools,
                "temperature": 0.1,
                "top_k": 20,
                "top_p": 0.8,
                "max_output_tokens": 8192,
            }
            if self.supports_thinking:
                config_args["thinking_config"] = types.ThinkingConfig(
                    include_thoughts=True,
                    thinking_budget=2048
                )
            
            config = types.GenerateContentConfig(**config_args)

            # --- MODIFIED: Add 4 second delay before every request ---
            console.print("[dim yellow]‚è≥ Waiting 4 seconds before request...[/dim yellow]")
            time.sleep(4)
            
            # --- MODIFIED: Add more robust retry logic ---
            response = None
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    response = self.client.models.generate_content(
                        model=AVAILABLE_MODELS[self.model_key],
                        contents=chat_history,
                        config=config
                    )
                    break
                # Catch the more general API error from Google's libraries
                except google_exceptions.GoogleAPICallError as e:
                    # Check the content of the error to see if it's a rate limit issue
                    error_str = str(e).upper()
                    if "RESOURCE_EXHAUSTED" in error_str or "429" in error_str:
                        wait_time = 60
                        
                        match = re.search(r"'retryDelay': '(\d+)s'", str(e))
                        if match:
                            wait_time = int(match.group(1)) + 2

                        panel_text = Text(f"Rate limit hit. Waiting for {wait_time}s before retrying ({attempt + 1}/{max_retries}).", style="bold yellow")
                        console.print(Panel(panel_text, title="[yellow]Rate Limit Handler[/yellow]", border_style="yellow"))
                        
                        if attempt + 1 >= max_retries:
                            console.print("[bold red]‚ùå CRITICAL: Max retries reached. Aborting run.[/bold red]")
                            raise e
                            
                        time.sleep(wait_time)
                    else:
                        # If it's a different API error (e.g., Permission Denied), don't retry.
                        console.print(f"[bold red]‚ùå An unexpected, non-retriable API error occurred: {e}[/bold red]")
                        self._log(f"\n--- NON-RETRIABLE API ERROR ---\n{e}")
                        raise e # Re-raise the original exception
                except Exception as e:
                    console.print(f"[bold red]‚ùå A critical unexpected error occurred: {e}[/bold red]")
                    self._log(f"\n--- CRITICAL UNEXPECTED ERROR ---\n{e}")
                    raise e
            
            if not response:
                return "Agent failed to get a response from the API after multiple retries."
            # --- END MODIFICATION ---
            
            # Extract and display token usage information
            if hasattr(response, 'usage_metadata') and response.usage_metadata:
                usage = response.usage_metadata
                prompt_tokens = getattr(usage, 'prompt_token_count', 0)
                output_tokens = getattr(usage, 'candidates_token_count', 0)
                thought_tokens = getattr(usage, 'thoughts_token_count', 0)
                total_tokens = getattr(usage, 'total_token_count', 0)
                
                token_text = Text(f"üìä Tokens: Prompt={prompt_tokens} | Output={output_tokens} | Thoughts={thought_tokens} | Total={total_tokens} | Model: {self.model_key} | Supports Thinking: {self.supports_thinking} | Turn: {turn + 1}/{max_turns}", style="dim cyan")
                console.print(Panel(token_text, style="dim blue", padding=(0, 1)))

            # --- MODIFIED: Log the raw response and verbose data ---
            self._log(f"\n--- Raw Response from Model ---\n{pformat(response)}")

            if self.verbose:
                console.print("[bold magenta]‚¨ÖÔ∏è Received Raw Response From Model...[/bold magenta]")
                pprint(response)
                console.print("-" * 20)

            candidate = response.candidates[0]
            parts = candidate.content.parts
            
            all_text_parts = [p.text.strip() for p in parts if hasattr(p, 'text') and p.text and p.text.strip()]
            tool_call_part = next((p for p in parts if hasattr(p, "function_call") and p.function_call), None)
            
            # print thought count when printing the rhought for supported thinking models
            # print("Thoughts tokens:",response.usage_metadata.thoughts_token_count)
            if all_text_parts:
                reasoning_text = "\n".join(all_text_parts)
                # if self.supports_thinking:
                #     console.print(f"**üí≠ Thought Count:** {response.usage_metadata.thoughts_token_count}")
                label = "**üí≠ Thought:**" if self.supports_thinking else "**üß† Reasoning:**"
                console.print(Markdown(f"{label}\n> {reasoning_text}"))
                self._log(f"\n--- Parsed Reasoning/Thought ---\n{reasoning_text}") # Log parsed text
            
            if tool_call_part:
                fn = tool_call_part.function_call
                fn_name = fn.name
                fn_args = {key: value for key, value in fn.args.items()}

                console.print(f"**üõ†Ô∏è Calling Tool:** `{fn_name}({fn_args})`")
                self._log(f"\n--- Tool Call ---\n{fn_name}({pformat(fn_args)})") # Log tool call

                tool_func = self.tool_handlers.get(fn_name)
                if tool_func:
                    result = tool_func(**fn_args)
                else:
                    result = f"Tool {fn_name} not found."

                print("Output tokens:",response.usage_metadata.candidates_token_count)
                console.print(Markdown(f"**üî¨ Observation:**\n```\n{result}\n```"))
                self._log(f"\n--- Tool Observation ---\n{result}") # Log tool result
                # print output tokens when printing the output everytime
                tool_response_part = types.Part.from_function_response(name=fn_name, response={"result": result})
                chat_history.append(candidate.content)
                chat_history.append(types.Content(role="tool", parts=[tool_response_part]))
            
            else:
                console.print(Markdown(f"**‚úÖ Agent has concluded its investigation.**"))
                if len(all_text_parts) > 1:
                    final_report = all_text_parts[-1]
                elif all_text_parts:
                    final_report = all_text_parts[0]
                else:
                    final_report = "Agent finished without a textual report."
                break

        # --- MODIFIED: Log the final report ---
        final_report_text = final_report or "Agent reached maximum turns without providing a final report."
        self._log(f"\n\n{'='*20} FINAL REPORT {'='*20}\n{final_report_text}")
        return final_report_text
    